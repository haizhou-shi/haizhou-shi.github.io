---
title: "Training-Free Bayesianization for Low-Rank Adapters of Large Language Models"
collection: publications
permalink: /publication/2024-12-07-tfb
tldr: "We introduce Training-Free Bayesianization (TFB), a method that converts existing LoRA adapters into Bayesian models without requiring additional training to estimate uncertainty in Large Language Models. TFB works by searching for optimal variance in the weight posterior within certain constraints, which we prove is equivalent to variational inference under certain conditions."
date: 2024-12-07'
venue: '<i>Arxiv preprint,</i> 2024.'
paperurl: 'https://arxiv.org/abs/2412.05723'
codeurl: 'https://github.com/Wang-ML-Lab/bayesian-peft'
img: '/images/publications/tfb.png'
authors: "<b>Haizhou Shi</b>*, Yibin Wang*, Ligong Han, Huan Zhang, Hao Wang"
selected: true
---